{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_for_date(year, month=None, start=True):\n",
    "    \"\"\"\n",
    "    Convert a year and optional month to a Unix timestamp (Epoch time).\n",
    "    \n",
    "    Args:\n",
    "        year (int): The year to convert\n",
    "        month (int, optional): The month to convert (1-12). If None, uses entire year.\n",
    "        start (bool): If True, returns timestamp for beginning of period\n",
    "                      If False, returns timestamp for end of period\n",
    "    \n",
    "    Returns:\n",
    "        int: Unix timestamp\n",
    "    \"\"\"\n",
    "    if month is None:\n",
    "        # Handle year-level timestamps\n",
    "        if start:\n",
    "            date_obj = datetime(year, 1, 1, 0, 0, 0)\n",
    "        else:\n",
    "            date_obj = datetime(year, 12, 31, 23, 59, 59)\n",
    "    else:\n",
    "        # Handle month-level timestamps\n",
    "        if month < 1 or month > 12:\n",
    "            raise ValueError(\"Month must be between 1 and 12\")\n",
    "            \n",
    "        if start:\n",
    "            date_obj = datetime(year, month, 1, 0, 0, 0)\n",
    "        else:\n",
    "            # Determine last day of month\n",
    "            import calendar\n",
    "            last_day = calendar.monthrange(year, month)[1]\n",
    "            date_obj = datetime(year, month, last_day, 23, 59, 59)\n",
    "    \n",
    "    return int(date_obj.timestamp())\n",
    "\n",
    "\n",
    "def get_news_by_ticker_and_period(ticker, year, month=None, api_key=None, page_size=40, wait_time=5):\n",
    "    \"\"\"\n",
    "    Retrieve news for a specific ticker and time period using the Seeking Alpha API.\n",
    "    Gets ALL available pages of results with a configurable wait time between requests.\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): Stock ticker symbol (e.g., 'AAPL')\n",
    "        year (int): Year to retrieve news for\n",
    "        month (int, optional): Specific month (1-12) to retrieve news for. If None, retrieves for entire year.\n",
    "        api_key (str): Your RapidAPI key\n",
    "        page_size (int): Number of results per page (max 40 as per API limits)\n",
    "        wait_time (int): Number of seconds to wait between API requests to avoid rate limiting\n",
    "    \n",
    "    Returns:\n",
    "        list: List of news items\n",
    "    \"\"\"\n",
    "    if api_key is None:\n",
    "        raise ValueError(\"API key is required\")\n",
    "    url = \"https://seeking-alpha.p.rapidapi.com/news/v2/list-by-symbol\"\n",
    "    \n",
    "    headers = {\n",
    "        \"x-rapidapi-key\": api_key,\n",
    "        \"x-rapidapi-host\": \"seeking-alpha.p.rapidapi.com\"\n",
    "    }\n",
    "    \n",
    "    # Convert year/month to start and end timestamps\n",
    "    since_timestamp = timestamp_for_date(year, month, start=True)\n",
    "    until_timestamp = timestamp_for_date(year, month, start=False)\n",
    "    \n",
    "    all_news = []\n",
    "    page_number = 1\n",
    "    more_pages = True\n",
    "    period_desc = f\"{year}\" if month is None else f\"{year}-{month:02d}\"\n",
    "    \n",
    "    while more_pages:\n",
    "        querystring = {\n",
    "            \"id\": ticker.lower(),\n",
    "            \"size\": str(page_size),\n",
    "            \"number\": str(page_number),\n",
    "            \"since\": str(since_timestamp),\n",
    "            \"until\": str(until_timestamp)\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            print(f\"Requesting page {page_number} for {ticker} - {period_desc}...\")\n",
    "            response = requests.get(url, headers=headers, params=querystring)\n",
    "            response.raise_for_status()  # Raise exception for 4XX/5XX responses\n",
    "            \n",
    "            data = response.json()\n",
    "            \n",
    "            # Check if we have news items\n",
    "            if 'data' in data and data['data']:\n",
    "                news_count = len(data['data'])\n",
    "                all_news.extend(data['data'])\n",
    "                print(f\"Retrieved page {page_number} with {news_count} news items for {ticker} - {period_desc}\")\n",
    "                \n",
    "                # If fewer items than page_size, we've reached the end\n",
    "                if news_count < page_size:\n",
    "                    more_pages = False\n",
    "                    print(f\"Reached end of results (received {news_count} < {page_size})\")\n",
    "                else:\n",
    "                    page_number += 1\n",
    "                    # Wait between requests to avoid rate limiting\n",
    "                    print(f\"Waiting {wait_time} seconds before next request...\")\n",
    "                    time.sleep(wait_time)\n",
    "            else:\n",
    "                more_pages = False\n",
    "                print(f\"No more news found after page {page_number-1}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving page {page_number}: {str(e)}\")\n",
    "            print(f\"Waiting {wait_time*2} seconds and then retrying...\")\n",
    "            time.sleep(wait_time*2)  # Wait longer on error before retry\n",
    "            \n",
    "            # Retry the same page once more\n",
    "            try:\n",
    "                response = requests.get(url, headers=headers, params=querystring)\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                data = response.json()\n",
    "                \n",
    "                if 'data' in data and data['data']:\n",
    "                    news_count = len(data['data'])\n",
    "                    all_news.extend(data['data'])\n",
    "                    print(f\"Retry successful! Retrieved page {page_number} with {news_count} news items\")\n",
    "                    \n",
    "                    if news_count < page_size:\n",
    "                        more_pages = False\n",
    "                        print(f\"Reached end of results (received {news_count} < {page_size})\")\n",
    "                    else:\n",
    "                        page_number += 1\n",
    "                        print(f\"Waiting {wait_time} seconds before next request...\")\n",
    "                        time.sleep(wait_time)\n",
    "                else:\n",
    "                    more_pages = False\n",
    "                    print(f\"No more news found after retry\")\n",
    "            except Exception as retry_error:\n",
    "                print(f\"Retry failed: {str(retry_error)}\")\n",
    "                more_pages = False\n",
    "    \n",
    "    total_retrieved = len(all_news)\n",
    "    print(f\"Total news items retrieved for {ticker} - {period_desc}: {total_retrieved}\")\n",
    "    return all_news\n",
    "\n",
    "\n",
    "def news_to_dataframe(news_items):\n",
    "    \"\"\"\n",
    "    Convert news items to a pandas DataFrame for easier analysis.\n",
    "    \n",
    "    Args:\n",
    "        news_items (list): List of news items from the API\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing news data\n",
    "    \"\"\"\n",
    "    if not news_items:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for item in news_items:\n",
    "        # Extract relevant fields (adjust based on actual API response structure)\n",
    "        news_data = {\n",
    "            'id': item.get('id'),\n",
    "            'title': item.get('attributes', {}).get('title', ''),\n",
    "            'published_at': item.get('attributes', {}).get('publishOn', ''),\n",
    "            'author': item.get('attributes', {}).get('getAuthor', {}).get('name', ''),\n",
    "            'url': f\"https://seekingalpha.com{item.get('links', {}).get('self', '')}\" if 'links' in item and 'self' in item['links'] else '',\n",
    "            # 'content': item.get('attributes', {}).get('content', ''),\n",
    "        }\n",
    "        data.append(news_data)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Convert published_at to datetime\n",
    "    if 'published_at' in df.columns:\n",
    "        df['published_at'] = pd.to_datetime(df['published_at'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_stock_news(ticker, year=None, month=None, api_key=None, range_years=None, range_months=None, wait_time=5):\n",
    "    \"\"\"\n",
    "    Main function to retrieve and format stock news for a specific ticker and time period.\n",
    "    Can handle single month/year or ranges of months/years to minimize API calls.\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): Stock ticker symbol (e.g., 'AAPL')\n",
    "        year (int, optional): Year to retrieve news for\n",
    "        month (int, optional): Month to retrieve news for (1-12)\n",
    "        api_key (str): Your RapidAPI key\n",
    "        range_years (tuple, optional): Tuple of (start_year, end_year) inclusive\n",
    "        range_months (tuple, optional): Tuple of (start_month, end_month) inclusive for use with a single year\n",
    "        wait_time (int): Number of seconds to wait between API requests\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing news data\n",
    "    \"\"\"\n",
    "    if api_key is None:\n",
    "        raise ValueError(\"API key is required\")\n",
    "        \n",
    "    all_news_items = []\n",
    "    \n",
    "    # Case 1: Range of years specified\n",
    "    if range_years is not None:\n",
    "        start_year, end_year = range_years\n",
    "        for y in range(start_year, end_year + 1):\n",
    "            if range_months is not None and y == start_year:\n",
    "                # For the start year, respect range_months\n",
    "                start_month, _ = range_months\n",
    "                for m in range(start_month, 13):\n",
    "                    items = get_news_by_ticker_and_period(ticker, y, m, api_key, wait_time=wait_time)\n",
    "                    all_news_items.extend(items)\n",
    "                    # Additional wait between months\n",
    "                    print(f\"Waiting {wait_time} seconds between months...\")\n",
    "                    time.sleep(wait_time)\n",
    "            elif range_months is not None and y == end_year:\n",
    "                # For the end year, respect range_months\n",
    "                _, end_month = range_months\n",
    "                for m in range(1, end_month + 1):\n",
    "                    items = get_news_by_ticker_and_period(ticker, y, m, api_key, wait_time=wait_time)\n",
    "                    all_news_items.extend(items)\n",
    "                    # Additional wait between months\n",
    "                    if m < end_month:  # Don't wait after the last month\n",
    "                        print(f\"Waiting {wait_time} seconds between months...\")\n",
    "                        time.sleep(wait_time)\n",
    "            else:\n",
    "                # For middle years or when range_months is None, get full year\n",
    "                items = get_news_by_ticker_and_period(ticker, y, None, api_key, wait_time=wait_time)\n",
    "                all_news_items.extend(items)\n",
    "            \n",
    "            # Additional wait between years\n",
    "            if y < end_year:  # Don't wait after the last year\n",
    "                print(f\"Waiting {wait_time*2} seconds between years...\")\n",
    "                time.sleep(wait_time*2)\n",
    "    \n",
    "    # Case 2: Single year with range of months\n",
    "    elif year is not None and range_months is not None:\n",
    "        start_month, end_month = range_months\n",
    "        for m in range(start_month, end_month + 1):\n",
    "            items = get_news_by_ticker_and_period(ticker, year, m, api_key, wait_time=wait_time)\n",
    "            all_news_items.extend(items)\n",
    "            # Additional wait between months\n",
    "            if m < end_month:  # Don't wait after the last month\n",
    "                print(f\"Waiting {wait_time} seconds between months...\")\n",
    "                time.sleep(wait_time)\n",
    "    \n",
    "    # Case 3: Single year, single month\n",
    "    elif year is not None and month is not None:\n",
    "        all_news_items = get_news_by_ticker_and_period(ticker, year, month, api_key, wait_time=wait_time)\n",
    "        \n",
    "    # Case 4: Single year, all months\n",
    "    elif year is not None:\n",
    "        all_news_items = get_news_by_ticker_and_period(ticker, year, None, api_key, wait_time=wait_time)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Must specify either year or range_years\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = news_to_dataframe(all_news_items)\n",
    "    \n",
    "    # Report results\n",
    "    period_desc = \"\"\n",
    "    if range_years:\n",
    "        start_y, end_y = range_years\n",
    "        period_desc = f\"years {start_y}-{end_y}\"\n",
    "    else:\n",
    "        period_desc = f\"year {year}\"\n",
    "        if month:\n",
    "            period_desc += f\", month {month}\"\n",
    "    \n",
    "    print(f\"Retrieved {len(df)} total news items for {ticker} in {period_desc}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"a9065dc5d4mshfe28e7f02070e41p1d065cjsn176eb4fe0609\"\n",
    "\n",
    "# # Get news for a range of years (useful for collecting 5 years of data)\n",
    "# apple_news = get_stock_news(\"AAPL\", api_key=API_KEY, range_years=(2019, 2025))\n",
    "\n",
    "# if not apple_news.empty:\n",
    "#     print(apple_news.head())\n",
    "    \n",
    "#     # Save to CSV\n",
    "#     apple_news.to_csv(\"AAPL_news_2019-2025.csv\", index=False)\n",
    "\n",
    "# load AAPL_news_2019-2025.csv\n",
    "apple_news = pd.read_csv(\"AAPL_news_2019-2025.csv\")\n",
    "apple_news = apple_news.drop(columns=['author'])\n",
    "apple_news.to_csv(\"AAPL_news_2019-2025_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
